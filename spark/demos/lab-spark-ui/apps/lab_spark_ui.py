import time

from pyspark.sql import SparkSession
from pyspark.sql.functions import avg, col, count, desc
from pyspark.sql.functions import sum as spark_sum

spark = (
    SparkSession.builder.appName("LAB_Spark_UI_Visualisation")
    .master("spark://spark-master:7077")
    .config("spark.executor.memory", "512m")
    .config("spark.executor.cores", "1")
    .config("spark.sql.shuffle.partitions", "6")
    .getOrCreate()
)


spark.sparkContext.setLogLevel("WARN")
sc = spark.sparkContext


def pause(message, duree=10):
    """Pause pour observer Spark UI"""
    print("\n" + "=" * 70)
    print(f"â¸ï¸  {message}")
    print("=" * 70)
    print(f"â³ Pause de {duree} secondes pour observer Spark UI...")
    time.sleep(duree)
    print("âœ… On continue !\n")


def titre(texte):
    """Affiche un titre"""
    print("\n" + "=" * 70)
    print(f"ðŸ”· {texte}")
    print("=" * 70)


titre("BIENVENUE DANS LE LAB SPARK UI")
print("""
Ce lab va te montrer comment Spark exÃ©cute les opÃ©rations :

ðŸ“Š ARCHITECTURE SPARK :

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                       DRIVER                      â”‚
    â”‚  (Ton programme Python - coordonne l'exÃ©cution)   â”‚
    â”‚  â†’ CrÃ©e le DAG (plan d'exÃ©cution)                 â”‚
    â”‚  â†’ DÃ©coupe en Jobs â†’ Stages â†’ Tasks               â”‚
    â”‚  â†’ Distribue les tasks aux Executors              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â–¼                 â–¼                 â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   EXECUTOR 1  â”‚ â”‚   EXECUTOR 2  â”‚ â”‚   EXECUTOR 3  â”‚
    â”‚   (Worker 1)  â”‚ â”‚   (Worker 2)  â”‚ â”‚   (Worker 3)  â”‚
    â”‚               â”‚ â”‚               â”‚ â”‚               â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚  â”‚ Task 1  â”‚  â”‚ â”‚  â”‚ Task 2  â”‚  â”‚ â”‚  â”‚ Task 3  â”‚  â”‚
    â”‚  â”‚ Task 4  â”‚  â”‚ â”‚  â”‚ Task 5  â”‚  â”‚ â”‚  â”‚ Task 6  â”‚  â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ðŸ“Œ VOCABULAIRE :
   â€¢ JOB    : DÃ©clenchÃ© par une ACTION (count, collect, show, write...)
   â€¢ STAGE  : Groupe de transformations sans shuffle
   â€¢ TASK   : UnitÃ© de travail sur 1 partition, exÃ©cutÃ©e par 1 executor
   â€¢ SHUFFLE: Redistribution des donnÃ©es entre stages (coÃ»teux !)
""")

pause(
    "Ouvre http://localhost:8080 pour voir le cluster, puis http://localhost:4040", 15
)


titre("Ã‰TAPE 1 : PREMIER JOB - count()")
print("""
On va crÃ©er un RDD et appeler count().

ðŸ“Œ CE QUI VA SE PASSER :
   1. Le Driver crÃ©e le DAG (plan d'exÃ©cution)
   2. count() est une ACTION â†’ dÃ©clenche un JOB
   3. Le JOB est dÃ©coupÃ© en TASKS (1 par partition)
   4. Les TASKS sont envoyÃ©es aux EXECUTORS
   5. Les rÃ©sultats remontent au DRIVER
""")


print("\nðŸ“Š CrÃ©ation d'un RDD avec 6 partitions...")
rdd = sc.parallelize(range(1, 1000001), numSlices=6)
print(f"   Nombre de partitions : {rdd.getNumPartitions()}")

pause("Observe dans Spark UI : rien ne s'est passÃ© ! (lazy evaluation)", 8)

print("ðŸ“Š ExÃ©cution de count() - ACTION qui dÃ©clenche un JOB...")
start = time.time()
resultat = rdd.count()
duree = time.time() - start

print(f"   RÃ©sultat : {resultat:,} Ã©lÃ©ments")
print(f"   DurÃ©e : {duree:.2f}s")

pause(
    """OBSERVE DANS SPARK UI (http://localhost:4040) :
   â†’ Onglet 'Jobs' : 1 job crÃ©Ã© (Job 0)
   â†’ Clique sur le job pour voir les STAGES
   â†’ Clique sur le stage pour voir les TASKS (6 tasks = 6 partitions)
   â†’ Onglet 'Executors' : voir quel executor a traitÃ© quelles tasks""",
    15,
)


titre("Ã‰TAPE 2 : TRANSFORMATIONS ET DAG")
print("""
Les TRANSFORMATIONS sont lazy (pas exÃ©cutÃ©es immÃ©diatement).
Spark construit un DAG (Directed Acyclic Graph) qui sera
exÃ©cutÃ© lors de la prochaine ACTION.

ðŸ“Œ TRANSFORMATIONS Ã€ APPLIQUER :
   1. map()    â†’ multiplier par 2
   2. filter() â†’ garder les > 500000
   3. map()    â†’ convertir en tuple (valeur, 1)
""")

print("\nðŸ“Š Application des transformations (lazy)...")
rdd_transforme = (
    rdd.map(lambda x: x * 2).filter(lambda x: x > 500000).map(lambda x: (x % 10, x))
)

print("   âœ… Transformations dÃ©finies (mais pas exÃ©cutÃ©es !)")

pause("Observe Spark UI : toujours 1 seul job ! Les transformations sont lazy", 8)

print("ðŸ“Š ExÃ©cution de count() - DÃ©clenche le calcul du DAG complet...")
start = time.time()
resultat = rdd_transforme.count()
duree = time.time() - start

print(f"   RÃ©sultat : {resultat:,} Ã©lÃ©ments")
print(f"   DurÃ©e : {duree:.2f}s")

pause(
    """OBSERVE DANS SPARK UI :
   â†’ Job 1 crÃ©Ã©
   â†’ Clique sur le job â†’ 'DAG Visualization'
   â†’ Tu vois le graphe : parallelize â†’ map â†’ filter â†’ map â†’ count
   â†’ Tout est dans 1 SEUL STAGE (pas de shuffle)""",
    15,
)


titre("Ã‰TAPE 3 : SHUFFLE - CRÃ‰ATION DE PLUSIEURS STAGES")
print("""
Certaines opÃ©rations nÃ©cessitent un SHUFFLE (redistribution des donnÃ©es) :
   â€¢ reduceByKey, groupByKey
   â€¢ join, cogroup
   â€¢ sortBy, orderBy
   â€¢ repartition

ðŸ“Œ LE SHUFFLE :
   1. Les donnÃ©es sont Ã©crites sur disque (shuffle write)
   2. RedistribuÃ©es entre executors par clÃ©
   3. Lues par le stage suivant (shuffle read)
   â†’ TrÃ¨s COÃ›TEUX en I/O rÃ©seau et disque !

ðŸ“Œ CE QUI VA SE PASSER :
   â€¢ Stage 1 : map + filter + map (narrow transformations)
   â€¢ SHUFFLE (redistribution par clÃ©)
   â€¢ Stage 2 : reduceByKey (agrÃ©gation)
""")

print("\nðŸ“Š OpÃ©ration avec SHUFFLE : reduceByKey...")
rdd_grouped = rdd.map(lambda x: (x % 5, x)).reduceByKey(lambda a, b: a + b)

start = time.time()
resultats = rdd_grouped.collect()
duree = time.time() - start

print(f"   RÃ©sultats : {resultats[:5]}...")
print(f"   DurÃ©e : {duree:.2f}s")

pause(
    """OBSERVE DANS SPARK UI :
   â†’ Job 2 crÃ©Ã©
   â†’ Clique dessus : tu vois 2 STAGES !
   â†’ Stage 0 : parallelize â†’ map (avant shuffle)
   â†’ Stage 1 : reduceByKey (aprÃ¨s shuffle)
   â†’ Dans chaque stage, clique pour voir les TASKS
   â†’ Onglet 'Stages' : voir 'Shuffle Read' et 'Shuffle Write'""",
    20,
)


titre("Ã‰TAPE 4 : SHUFFLE COMPLEXE AVEC JOIN")
print("""
Un JOIN entre deux RDD crÃ©e un SHUFFLE important :
   â€¢ Les donnÃ©es des deux RDD sont redistribuÃ©es par clÃ©
   â€¢ Les partitions avec la mÃªme clÃ© se retrouvent sur le mÃªme executor

ðŸ“Œ CE QUI VA SE PASSER :
   â€¢ RDD 1 : utilisateurs (id, nom)
   â€¢ RDD 2 : commandes (id_user, montant)
   â€¢ JOIN sur id_user
   â†’ 3 stages : prÃ©paration RDD1, prÃ©paration RDD2, join
""")


print("\nðŸ“Š CrÃ©ation des RDD...")
rdd_users = sc.parallelize(
    [(1, "Alice"), (2, "Bob"), (3, "Charlie"), (4, "David"), (5, "Eve"), (6, "Frank")],
    numSlices=3,
)

rdd_commandes = sc.parallelize(
    [
        (1, 100),
        (1, 200),
        (2, 150),
        (2, 300),
        (3, 250),
        (4, 175),
        (5, 400),
        (5, 125),
        (6, 350),
        (1, 275),
    ],
    numSlices=3,
)

print("   RDD users : 6 utilisateurs")
print("   RDD commandes : 10 commandes")

print("\nðŸ“Š JOIN des deux RDD...")
start = time.time()
rdd_join = rdd_users.join(rdd_commandes)
resultats = rdd_join.collect()
duree = time.time() - start

print(f"   RÃ©sultats du join : {len(resultats)} lignes")
for r in resultats[:5]:
    print(f"      User {r[0]}: {r[1][0]} â†’ {r[1][1]}â‚¬")
print(f"   DurÃ©e : {duree:.2f}s")

pause(
    """OBSERVE DANS SPARK UI :
   â†’ Nouveau job avec PLUSIEURS STAGES
   â†’ Le DAG montre les 2 RDD qui convergent vers le join
   â†’ Observe le 'Shuffle Read Size' dans les stages
   â†’ Compare la taille des donnÃ©es avant/aprÃ¨s shuffle""",
    15,
)


titre("Ã‰TAPE 5 : VISUALISER L'EFFET DU CACHE")
print("""
Sans CACHE, chaque action recalcule tout le DAG.
Avec CACHE, le rÃ©sultat est stockÃ© en mÃ©moire.

ðŸ“Œ CE QU'ON VA FAIRE :
   1. CrÃ©er un RDD avec transformations coÃ»teuses
   2. ExÃ©cuter 3 actions SANS cache â†’ 3 recalculs
   3. Mettre en cache
   4. ExÃ©cuter 3 actions AVEC cache â†’ 1 calcul + 2 lectures
""")


print("\nðŸ“Š CrÃ©ation du RDD avec transformations...")
rdd_complexe = (
    sc.parallelize(range(1, 500001), numSlices=6)
    .map(lambda x: (x % 100, x * 2))
    .filter(lambda x: x[1] > 100000)
)


print("\nðŸ”´ SANS CACHE - 3 actions successives...")
start = time.time()
count1 = rdd_complexe.count()
sum1 = rdd_complexe.map(lambda x: x[1]).sum()
max1 = rdd_complexe.map(lambda x: x[1]).max()
duree_sans = time.time() - start
print(f"   Count: {count1}, Sum: {sum1}, Max: {max1}")
print(f"   DurÃ©e totale : {duree_sans:.2f}s")

pause(
    """OBSERVE DANS SPARK UI :
   â†’ 3 nouveaux JOBS crÃ©Ã©s (un par action)
   â†’ Chaque job recalcule TOUT le DAG
   â†’ Pas de donnÃ©es en cache (onglet 'Storage' vide)""",
    15,
)


print("\nðŸŸ¢ AVEC CACHE - 3 actions successives...")
rdd_cache = (
    sc.parallelize(range(1, 500001), numSlices=6)
    .map(lambda x: (x % 100, x * 2))
    .filter(lambda x: x[1] > 100000)
)

rdd_cache.cache()
print("   âœ… RDD marquÃ© pour cache")

start = time.time()
count2 = rdd_cache.count()
sum2 = rdd_cache.map(lambda x: x[1]).sum()
max2 = rdd_cache.map(lambda x: x[1]).max()
duree_avec = time.time() - start
print(f"   Count: {count2}, Sum: {sum2}, Max: {max2}")
print(f"   DurÃ©e totale : {duree_avec:.2f}s")

if duree_sans > duree_avec:
    print(f"\n   ðŸš€ Gain avec cache : {(1 - duree_avec / duree_sans) * 100:.1f}%")

pause(
    """OBSERVE DANS SPARK UI :
   â†’ Onglet 'Storage' : le RDD est maintenant en cache !
   â†’ Tu vois la taille en mÃ©moire et le % mis en cache
   â†’ Les jobs suivants sont plus rapides (lisent le cache)
   â†’ Dans le DAG, une icÃ´ne verte indique le cache""",
    15,
)


rdd_cache.unpersist()


titre("Ã‰TAPE 6 : DATAFRAME - PLAN D'EXÃ‰CUTION CATALYST")
print("""
Avec les DataFrames, Spark utilise l'optimiseur CATALYST
qui crÃ©e un plan d'exÃ©cution optimisÃ©.

ðŸ“Œ TU PEUX VOIR :
   â€¢ Le plan LOGIQUE (ce que tu as demandÃ©)
   â€¢ Le plan PHYSIQUE (comment Spark va l'exÃ©cuter)
   â€¢ Les optimisations appliquÃ©es (predicate pushdown, etc.)
""")


print("\nðŸ“Š CrÃ©ation d'un DataFrame de ventes...")
data = [
    (
        f"client_{i}",
        f"produit_{i % 10}",
        i * 10.5,
        "2024-01-" + str((i % 28) + 1).zfill(2),
    )
    for i in range(1, 10001)
]

df = spark.createDataFrame(data, ["client", "produit", "montant", "date"])
print(f"   {df.count()} lignes crÃ©Ã©es")


print("\nðŸ“Š RequÃªte complexe : top 5 clients par montant total...")
df_result = (
    df.filter(col("montant") > 50)
    .groupBy("client")
    .agg(
        spark_sum("montant").alias("total"),
        count("*").alias("nb_achats"),
        avg("montant").alias("moyenne"),
    )
    .orderBy(desc("total"))
    .limit(5)
)


print("\nðŸ“‹ PLAN D'EXÃ‰CUTION :")
df_result.explain(mode="extended")


print("\nðŸ“Š RÃ©sultat :")
df_result.show()

pause(
    """OBSERVE DANS SPARK UI :
   â†’ Onglet 'SQL' : tu vois la requÃªte et son plan
   â†’ Clique sur la requÃªte pour voir le DAG dÃ©taillÃ©
   â†’ Les opÃ©rations sont optimisÃ©es par Catalyst
   â†’ Tu vois les mÃ©triques : lignes lues, shuffles, etc.""",
    15,
)


titre("Ã‰TAPE 7 : BROADCAST JOIN VS SHUFFLE JOIN")
print("""
Quand tu fais un JOIN, Spark peut utiliser :
   â€¢ SHUFFLE JOIN : redistribue les deux tables (coÃ»teux)
   â€¢ BROADCAST JOIN : envoie la petite table Ã  tous les executors

ðŸ“Œ BROADCAST JOIN :
   â€¢ Pas de shuffle de la grande table
   â€¢ La petite table est copiÃ©e sur chaque executor
   â€¢ Beaucoup plus rapide !
""")


print("\nðŸ“Š CrÃ©ation des tables...")
df_ventes = spark.createDataFrame(
    [(i, f"P{i % 20}", i * 1.5) for i in range(1, 100001)],
    ["vente_id", "produit_id", "montant"],
)
print(f"   Table ventes : {df_ventes.count()} lignes")


df_produits = spark.createDataFrame(
    [(f"P{i}", f"Produit {i}", f"Cat{i % 5}") for i in range(20)],
    ["produit_id", "nom_produit", "categorie"],
)
print(f"   Table produits : {df_produits.count()} lignes")


from pyspark.sql.functions import broadcast

print("\nðŸ“Š BROADCAST JOIN...")
start = time.time()
df_join = df_ventes.join(broadcast(df_produits), "produit_id")
count_join = df_join.count()
duree = time.time() - start
print(f"   RÃ©sultat : {count_join} lignes en {duree:.2f}s")

pause(
    """OBSERVE DANS SPARK UI :
   â†’ Onglet 'SQL' : clique sur la derniÃ¨re requÃªte
   â†’ Dans le plan, tu vois 'BroadcastHashJoin'
   â†’ Pas de shuffle de la grande table !
   â†’ Compare avec un shuffle join (dÃ©sactive broadcast)""",
    15,
)


titre("Ã‰TAPE 8 : OBSERVER LES EXECUTORS EN ACTION")
print("""
On va lancer un job LONG pour observer les executors travailler.

ðŸ“Œ OBSERVE :
   â€¢ Onglet 'Executors' : CPU, mÃ©moire, tasks en cours
   â€¢ Onglet 'Stages' â†’ clique sur un stage actif
   â€¢ Tu vois les tasks s'exÃ©cuter en temps rÃ©el !
   â€¢ La barre de progression des tasks
""")

print("\nðŸ“Š Lancement d'un job long (20 partitions)...")
import time as t


def travail_lent(x):
    """Simule un traitement lent"""
    t.sleep(0.01)
    return x * 2


rdd_long = sc.parallelize(range(1, 5001), numSlices=20)

print("   Job en cours... observe les executors !")
start = time.time()
resultat = rdd_long.map(travail_lent).count()
duree = time.time() - start

print(f"   TerminÃ© : {resultat} Ã©lÃ©ments en {duree:.2f}s")

pause(
    """AS-TU OBSERVÃ‰ ?
   â†’ Les tasks se distribuent sur les 3 workers
   â†’ Certains executors terminent avant d'autres (data skew)
   â†’ Le temps total = temps du plus lent executor""",
    10,
)


titre("RÃ‰SUMÃ‰ - CE QUE TU AS APPRIS")
print("""
ðŸ“Š ARCHITECTURE :
   â€¢ DRIVER : coordonne, crÃ©e le DAG, distribue les tasks
   â€¢ EXECUTOR : exÃ©cute les tasks, stocke les donnÃ©es en cache
   â€¢ TASK : unitÃ© de travail sur 1 partition

ðŸ“Š EXÃ‰CUTION :
   â€¢ ACTION â†’ dÃ©clenche un JOB
   â€¢ JOB â†’ dÃ©coupÃ© en STAGES (sÃ©parÃ©s par les shuffles)
   â€¢ STAGE â†’ contient des TASKS (1 par partition)

ðŸ“Š OPTIMISATIONS :
   â€¢ CACHE : Ã©vite de recalculer le DAG
   â€¢ BROADCAST : Ã©vite les shuffles pour les petites tables
   â€¢ PARTITIONING : contrÃ´le le parallÃ©lisme

ðŸ“Š SPARK UI (http://localhost:4040) :
   â€¢ Jobs : liste des actions exÃ©cutÃ©es
   â€¢ Stages : dÃ©tail des shuffles
   â€¢ Tasks : exÃ©cution sur les executors
   â€¢ Storage : RDD/DataFrames en cache
   â€¢ SQL : plans d'exÃ©cution Catalyst
   â€¢ Executors : Ã©tat des workers

ðŸ“Š URLS DU CLUSTER :
   â€¢ http://localhost:8080 â†’ Spark Master
   â€¢ http://localhost:4040 â†’ Application UI (driver)
   â€¢ http://localhost:8081 â†’ Worker 1
   â€¢ http://localhost:8082 â†’ Worker 2
   â€¢ http://localhost:8083 â†’ Worker 3
""")

pause("Lab terminÃ© ! Tu peux explorer Spark UI encore un peu avant de fermer", 30)

spark.stop()
print("\nâœ… Session Spark fermÃ©e. Ã€ bientÃ´t !")
