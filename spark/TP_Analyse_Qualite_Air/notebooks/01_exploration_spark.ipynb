{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4dbc9e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a51ad2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une session Spark locale.\n",
    "builder: SparkSession.Builder = SparkSession.builder\n",
    "spark = builder.master(\"local\").appName(\"01_exploration_spark\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e682f797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger `air_quality_raw.csv` en DataFrame Spark.\n",
    "air_quality = (\n",
    "    spark.read.option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .option(\"sep\", \",\")\n",
    "    .csv(\"data/air_quality_raw.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "36a06567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- station_id: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- pollutant: string (nullable = true)\n",
      " |-- value: string (nullable = true)\n",
      " |-- unit: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Afficher le schéma inféré et identifier les problèmes de typage.\n",
    "air_quality.printSchema()\n",
    "\n",
    "# Problèmes de typages :\n",
    "# timestamp : string -> datetime\n",
    "# value : string -> float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "afc85d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------------------+------------------+---+----+-----+-----+------+\n",
      "|pollutant|count |mean              |stddev            |min|max |Q1   |Q2   |Q3    |\n",
      "+---------+------+------------------+------------------+---+----+-----+-----+------+\n",
      "|PM10     |205130|70.21267468823174 |335.66700132196706|---|null|23.65|35.25|50.06 |\n",
      "|NO2      |205106|78.76389141237802 |340.0682280909494 |---|null|28.3 |42.41|60.23 |\n",
      "|O3       |205242|108.20850580284663|334.0956554017962 |---|null|47.15|70.46|100.24|\n",
      "|CO       |205083|33.244708332372745|338.5496147920897 |---|null|0.47 |0.71 |1.0   |\n",
      "|PM2.5    |205215|55.09891935232638 |335.55145568365253|---|null|14.16|21.17|30.12 |\n",
      "|SO2      |205175|41.00714578488003 |344.27247159941027|---|null|4.7  |7.04 |10.05 |\n",
      "+---------+------+------------------+------------------+---+----+-----+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculer des statistiques descriptives par polluant.\n",
    "df_summary = air_quality.groupBy(\"pollutant\").agg(\n",
    "    F.count(\"*\").alias(\"count\"),\n",
    "    F.avg(\"value\").alias(\"mean\"),\n",
    "    F.std(\"value\").alias(\"stddev\"),\n",
    "    F.min(\"value\").alias(\"min\"),\n",
    "    F.max(\"value\").alias(\"max\"),\n",
    "    F.percentile(\"value\", [0.25, 0.5, 0.75]).alias(\"quantiles\"),\n",
    ")\n",
    "df_summary = df_summary.withColumn(\n",
    "    \"Q1\",\n",
    "    F.col(\"quantiles\")[0],\n",
    ").withColumn(\n",
    "    \"Q2\",\n",
    "    F.col(\"quantiles\")[1],\n",
    ").withColumn(\n",
    "    \"Q3\",\n",
    "    F.col(\"quantiles\")[2],\n",
    ").drop(\"quantiles\")\n",
    "df_summary.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16aee709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------+--------------+----------+---------+\n",
      "|station_id_null|timestamp_null|pollutant_null|value_null|unit_null|\n",
      "+---------------+--------------+--------------+----------+---------+\n",
      "|              0|             0|             0|      1538|        0|\n",
      "+---------------+--------------+--------------+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compter les valeurs nulles par colonne.\n",
    "df_null = air_quality.select(\n",
    "    [\n",
    "        F.count(F.when((F.col(c).isNull()) | (F.col(c) == \"\") | (F.lower(F.col(c)) == \"null\"), c)).alias(c + \"_null\")\n",
    "        for c in air_quality.columns\n",
    "    ]\n",
    ")\n",
    "df_null.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0bfc1863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|station_id|count|\n",
      "+----------+-----+\n",
      "|    ST0032|26264|\n",
      "|    ST0012|26244|\n",
      "|    ST0028|26241|\n",
      "|    ST0003|26239|\n",
      "|    ST0029|26235|\n",
      "|    ST0024|26235|\n",
      "|    ST0020|26235|\n",
      "|    ST0037|26233|\n",
      "|    ST0023|26233|\n",
      "|    ST0042|26224|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Identifier les stations avec le plus d'enregistrements.\n",
    "top10_station = air_quality.groupBy(\"station_id\").count().orderBy(F.col(\"count\").desc()).limit(10)\n",
    "top10_station.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0e7d43ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
